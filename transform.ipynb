{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "joined_data = pd.read_csv('data/joined_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "joined_data[\"work_from_home\"] = joined_data[\"work_from_home\"].fillna('False')\n",
    "new_joined_data = joined_data[['id','description_tokens']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['vba', 'spreadsheet', 'javascript', 'word', 'sql', 'excel', 'r', 'python', 'sas', 'matlab', 'spss', 'spark', 'snowflake', 'scala', 'airflow', 'aws', 'alteryx', 'sap', 'go', 'numpy', 'scikit-learn', 'pandas', 'c', 'ssrs', 'ssis', 'azure', 'power_bi', 'powerpoint', 'postgresql', 'hadoop', 'looker', 'outlook', 'sharepoint', 'qlik', 'tableau', 'mysql', 'cognos', 'gcp', 'java', 'jira', 'atlassian', 'postgres', 'visio', 'shell', 'unix/linux', 'linux', 'perl', 'nuix', 'redshift', 'powerpoints', 'c++', 'bigquery', 'nosql', 't-sql', 'microstrategy', 'tensorflow', 'matplotlib', 'keras', 'gdpr', 'powershell', 'html', 'dax', 'github', 'mongodb', 'redis', 'pyspark', 'pl/sql', 'assembly', 'swift', 'aurora', 'selenium', 'css', 'splunk', 'git', 'mssql', 'julia', 'bash', 'vb.net', 'asp.net', 'jupyter', 'crystal', 'seaborn', 'docker', 'plotly', 'unix', 'node.js', 'terminal', 'visual_basic', 'bitbucket', 'fortran', 'php', 'jquery', 'typescript', 'js', 'no-sql', 'ruby', 'linux/unix', 'pytorch', 'mongo', 'ggplot2', 'dplyr', 'node', 'vue', 'c/c++', 'gitlab', 'rust', 'rshiny', 'golang', 'solidity', 'apl', 'cobol', 'groovy', 'twilio', 'vue.js', 'dart', 'graphql', 'tidyr']\n"
     ]
    }
   ],
   "source": [
    "uniqued = joined_data[\"description_tokens\"]\n",
    "skill = []\n",
    "for text in uniqued:\n",
    "    x = text.split(',')\n",
    "    for each in x:\n",
    "        y =each.strip(\"' .,!;()[]'\")\n",
    "        if y not in skill:\n",
    "            skill.append(y)\n",
    "        else:\n",
    "            continue\n",
    "skill.remove('')\n",
    "print(skill)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jonna\\AppData\\Local\\Temp\\ipykernel_15936\\3173936788.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  joined_data[each] = np.where(joined_data.description_tokens.str.contains(each,regex=True) == True, 1, 0)\n",
      "C:\\Users\\jonna\\AppData\\Local\\Temp\\ipykernel_15936\\3173936788.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  joined_data[each] = np.where(joined_data.description_tokens.str.contains(each,regex=True) == True, 1, 0)\n",
      "C:\\Users\\jonna\\AppData\\Local\\Temp\\ipykernel_15936\\3173936788.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  joined_data[each] = np.where(joined_data.description_tokens.str.contains(each,regex=True) == True, 1, 0)\n",
      "C:\\Users\\jonna\\AppData\\Local\\Temp\\ipykernel_15936\\3173936788.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  joined_data[each] = np.where(joined_data.description_tokens.str.contains(each,regex=True) == True, 1, 0)\n",
      "C:\\Users\\jonna\\AppData\\Local\\Temp\\ipykernel_15936\\3173936788.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  joined_data[each] = np.where(joined_data.description_tokens.str.contains(each,regex=True) == True, 1, 0)\n",
      "C:\\Users\\jonna\\AppData\\Local\\Temp\\ipykernel_15936\\3173936788.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  joined_data[each] = np.where(joined_data.description_tokens.str.contains(each,regex=True) == True, 1, 0)\n",
      "C:\\Users\\jonna\\AppData\\Local\\Temp\\ipykernel_15936\\3173936788.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  joined_data[each] = np.where(joined_data.description_tokens.str.contains(each,regex=True) == True, 1, 0)\n",
      "C:\\Users\\jonna\\AppData\\Local\\Temp\\ipykernel_15936\\3173936788.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  joined_data[each] = np.where(joined_data.description_tokens.str.contains(each,regex=True) == True, 1, 0)\n",
      "C:\\Users\\jonna\\AppData\\Local\\Temp\\ipykernel_15936\\3173936788.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  joined_data[each] = np.where(joined_data.description_tokens.str.contains(each,regex=True) == True, 1, 0)\n",
      "C:\\Users\\jonna\\AppData\\Local\\Temp\\ipykernel_15936\\3173936788.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  joined_data[each] = np.where(joined_data.description_tokens.str.contains(each,regex=True) == True, 1, 0)\n",
      "C:\\Users\\jonna\\AppData\\Local\\Temp\\ipykernel_15936\\3173936788.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  joined_data[each] = np.where(joined_data.description_tokens.str.contains(each,regex=True) == True, 1, 0)\n",
      "C:\\Users\\jonna\\AppData\\Local\\Temp\\ipykernel_15936\\3173936788.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  joined_data[each] = np.where(joined_data.description_tokens.str.contains(each,regex=True) == True, 1, 0)\n",
      "C:\\Users\\jonna\\AppData\\Local\\Temp\\ipykernel_15936\\3173936788.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  joined_data[each] = np.where(joined_data.description_tokens.str.contains(each,regex=True) == True, 1, 0)\n",
      "C:\\Users\\jonna\\AppData\\Local\\Temp\\ipykernel_15936\\3173936788.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  joined_data[each] = np.where(joined_data.description_tokens.str.contains(each,regex=True) == True, 1, 0)\n",
      "C:\\Users\\jonna\\AppData\\Local\\Temp\\ipykernel_15936\\3173936788.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  joined_data[each] = np.where(joined_data.description_tokens.str.contains(each,regex=True) == True, 1, 0)\n",
      "C:\\Users\\jonna\\AppData\\Local\\Temp\\ipykernel_15936\\3173936788.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  joined_data[each] = np.where(joined_data.description_tokens.str.contains(each,regex=True) == True, 1, 0)\n",
      "C:\\Users\\jonna\\AppData\\Local\\Temp\\ipykernel_15936\\3173936788.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  joined_data[each] = np.where(joined_data.description_tokens.str.contains(each,regex=True) == True, 1, 0)\n",
      "C:\\Users\\jonna\\AppData\\Local\\Temp\\ipykernel_15936\\3173936788.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  joined_data[each] = np.where(joined_data.description_tokens.str.contains(each,regex=True) == True, 1, 0)\n",
      "C:\\Users\\jonna\\AppData\\Local\\Temp\\ipykernel_15936\\3173936788.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  joined_data[each] = np.where(joined_data.description_tokens.str.contains(each,regex=True) == True, 1, 0)\n",
      "C:\\Users\\jonna\\AppData\\Local\\Temp\\ipykernel_15936\\3173936788.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  joined_data[each] = np.where(joined_data.description_tokens.str.contains(each,regex=True) == True, 1, 0)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "for each in skill: \n",
    "    joined_data[each] = np.where(joined_data.description_tokens.str.contains(each,regex=True) == True, 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "joined_data.to_csv('data/encoded_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data = joined_data[joined_data[\"salary_standardized\"].notna()]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data.to_csv('data/clean_data.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
